
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>random forest - 知行录</title>
  <meta name="author" content="阿波">

  
  <meta name="description" content="概述 知识背景要求 本文要求读者对机器学习中的一些基本概念有一定了解，比如特征，交叉验证，generation等概念。随机森林基于决策树模型，读者事先最好对决策树有一定的了解，若完全不了解，请将文中的tree抽象成能告诉你对错的一个black box，则不会影响理解。 目录 基本思想 理论保证 &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://whbzju.github.com/blog/2015/02/16/random-forest/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="知行录" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<!--link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css" -->
<!--link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css" -->
  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-16146431-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">知行录</a></h1>
  
    <h2>rethinking</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:whbzju.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">博客主页</a></li>
  <li><a href="/blog/archives">文章列表</a></li>
  <li><a href="/about">关于</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Random Forest</h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-02-16T15:09:00+08:00" pubdate data-updated="true">Feb 16<span>th</span>, 2015</time>
        
         | <a href="#disqus_thread">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><h2 id="section">概述</h2>

<h3 id="section-1">知识背景要求</h3>

<p>本文要求读者对机器学习中的一些基本概念有一定了解，比如特征，交叉验证，generation等概念。随机森林基于决策树模型，读者事先最好对决策树有一定的了解，若完全不了解，请将文中的tree抽象成能告诉你对错的一个black box，则不会影响理解。</p>

<h3 id="section-2">目录</h3>

<ol>
  <li>基本思想</li>
  <li>理论保证</li>
  <li>实践中常用的特性</li>
  <li>实践效果验证</li>
  <li>需要重点注意的</li>
  <li>参考</li>
</ol>

<h2 id="section-3">基本思想</h2>

<h3 id="ensemble-method">Ensemble method</h3>

<p>ensemble是当前主流机器学习领域一个非常流行的概念。引用sklearn的文档：</p>

<blockquote>
  <p>The goal of ensemble methods is to combine the predictions of several base estimators built with a given learning algorithm in order to improve generalizability / robustness over a single estimator.</p>
</blockquote>

<p>其又分为两大类：averaging和boosting，分别以Random Forest和AdaBoost算法为代表。</p>

<h3 id="random-forest">Random Forest</h3>

<p>引用wiki的定义：</p>

<blockquote>
  <p>Random forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. </p>
</blockquote>

<p>直白来讲，随机森林就是将一堆决策树聚在一起，形成一个森林，让每个决策树对测试目标投票，最后对结果求平均，得到最终结果。举个例子：今天你要预测中国队能不能进入世界杯，你找了一百个朋友，让他们每个人给个预测，最后对所有人的预测结果求平均，得到最后中国队能不能出线的结论。直观来理解，这个模型最终结果受到两个因素影响，这一百个朋友中每个人对足球的了解程度和这些人之间的差异程度。</p>

<p>换个正式点的描述：首先，我们假设你了解如果构造一个决策树，随机森林构造了很多个决策树，对于一个数据集N，每次随机抽取n个数据和m个特征，构造一个完全生长的树（不用剪枝），将数据放回重复上述过程，直到生成M棵树。其中有放回的抽样称为bootstrap，是非常重要的概念，下文中让随机森林不用交叉验证的out-of-bag理论基于此。在最初的那篇论文，提到该模型的error受两个因素影响：</p>

<pre><code>* 每个树之间的correction。correction增加，error增加。
* 单独一颗树的strength（不知道怎么翻译，能力？）。strength增加，error下降。
</code></pre>

<p>随机选取m个特征是个关键的步骤，假设总特征有M个，m越小，correction和strength越小。m越大，correction和strength越大。一个合理的m很重要。</p>

<h2 id="section-4">理论保证</h2>

<p>写公式好累，大家去看参考文献吧。</p>

<h2 id="section-5">常用特性</h2>

<ul>
  <li>oob </li>
  <li>feature importance</li>
  <li>聚类</li>
</ul>

<h3 id="the-out-of-bag-oob-error-estimate">The out-of-bag (oob) error estimate</h3>

<p>前面提到过boostrap，这个抽样机制从理论上决定了每次抽样有近三分之一的数据不会被抽到，即可以直接拿来做为测试集，使random forest免去cross validation的过程，节省了时间，称为oob。</p>

<h3 id="feature-importance">feature importance</h3>

<p>random forest是个black box，feature importance特性有助于模型的可解释性。简单考虑下，就算在解释性很强的决策树模型中，如果树过于庞大，人类也很难解释它做出的结果。随机森林通常会有上百棵树组成，更加难以解释。好在我们可以找到那些特征是更加重要的，从而辅助我们解释模型。更加重要的是可以剔除一些不重要的特征，降低杂讯。比起pca降维后的结果，更具有人类的可理解性。</p>

<p>feature importance有好几种方案实现，最常用的是基于一个思想：如果该特征非常的重要，那么稍微改变一点它的值，就会对模型造成很大的影响。再偷个懒，自己造数据太麻烦，可以直接在数据集对该维度的特征数据进行打乱，重新训练测试，打乱前的准确率减去打乱后的准确率就是该特征的重要度。该方法又叫permute。</p>

<h3 id="unsupervised-learning-">Unsupervised learning 聚类</h3>

<p>有点出乎意料，原来随机森林还可以做聚类。总所周知，聚类算法的关键是相识度计算，而随机森林能很好的做相识度计算。首先让我们了解下Proximities：</p>

<blockquote>
  <p>The proximities originally formed a NxN matrix. After a tree is grown, put all of the data, both training and oob, down the tree. If cases k and n are in the same terminal node increase their proximity by one. At the end, normalize the proximities by dividing by the number of trees.</p>
</blockquote>

<p>大致的意思是说，在随机森林模型生成时，统计case k和n在不在同一个叶子节点中，在就加1，最后在安装树的个数归一化。得到case之间的相似度。</p>

<h2 id="section-6">实践效果验证</h2>

<p>在工作中，随机森林被我用来做的最多的事情还是feature importance，验证自己的特征工程效果。另外，由于它的鲁棒性特别好，模型效果在各大模型中排中等，而且对数据预处理要求低，我经常会优先选择用它跑个benchmark。</p>

<p>业余时间还会玩玩kaggle比赛，它就用的比较多，其实gbdt应该更适合比赛，但我个人还是偏好RF。下面放个kaggle的比赛总结，关于如何用它：<a href="https://www.kaggle.com/c/titanic-gettingStarted/details/getting-started-with-random-forests">Getting Started with Random Forests: Titanic Competition</a></p>

<h2 id="section-7">需要重点注意的</h2>

<p>以sklearn的RandomForestClassifier为例，有几个参数需要调下。</p>

<ol>
  <li>n_estimators。决定模型有几颗树，我在做Click-Through Rate Prediction比赛时，将它从default 10改到100，模型效果提升了很多。</li>
  <li>criterion。默认有gini和entropy可选，到底哪个好现在还是有争论的。</li>
  <li>max_features，这个和n_estimators会一起影响整体结果，上文已经提到，可以参数换几个参数试试。</li>
</ol>

<h2 id="section-8">下一步计划</h2>

<p>研究下gradient boosting decision tree</p>

<h2 id="section-9">参考</h2>

<p><a href="http://en.wikipedia.org/wiki/Random_forest">1 wiki RF</a></p>

<p><a href="http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#inter">2 Random Forests Leo Breiman and Adele Cutler</a></p>

<p><a href="http://scikit-learn.org/stable/modules/ensemble.html">3 Ensemble methods</a></p>

</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">阿波</span></span>

      








  


<time datetime="2015-02-16T15:09:00+08:00" pubdate data-updated="true">Feb 16<span>th</span>, 2015</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/learning/'>learning</a>, <a class='category' href='/blog/categories/machine/'>machine</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2015/02/10/feature-hashing/" title="Previous Post: 机器学习技巧之feature_hashing">&laquo; 机器学习技巧之feature_hashing</a>
      
      
        <a class="basic-alignment right" href="/blog/2015/04/18/kaggle-bike/" title="Next Post: Kaggle入门总结">Kaggle入门总结 &raquo;</a>
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>About Me</h1>
  <p>ZJU CS小硕 爱读书 爱代码 相信移动互联网</p>
</section>

<section>
  <h1>新浪微博</h1>
  <ul id="weibo">
    <li>
      <iframe 
        width="100%" 
        height="550" 
        class="share_self" 
        frameborder="0" 
        scrolling="no" 
        src="http://widget.weibo.com/weiboshow/index.php?width=0&height=550&ptype=1&speed=0&skin=&isTitle=0&noborder=1&isWeibo=1&isFans=&uid=1911447995&verifier=4e804b1d">
      </iframe>
    </li>
  </ul>
</section>

<section>
	<h1>Categories</h1>
    	<ul id="categories">
	        <li><a href='/blog/categories/bussiness'>bussiness</a></li><li><a href='/blog/categories/c'>C</a></li><li><a href='/blog/categories/coding'>coding</a></li><li><a href='/blog/categories/git'>git</a></li><li><a href='/blog/categories/jni'>JNI</a></li><li><a href='/blog/categories/learning'>learning</a></li><li><a href='/blog/categories/mac'>Mac</a></li><li><a href='/blog/categories/machine'>machine</a></li><li><a href='/blog/categories/maching'>maching</a></li><li><a href='/blog/categories/octopress'>octopress</a></li><li><a href='/blog/categories/os'>OS</a></li><li><a href='/blog/categories/thoughts'>Thoughts</a></li><li><a href='/blog/categories/tryos'>TryOS</a></li><li><a href='/blog/categories/vim'>vim</a></li><li><a href='/blog/categories/公开课'>公开课</a></li><li><a href='/blog/categories/计步器'>计步器</a></li><li><a href='/blog/categories/读书'>读书</a></li>
	</ul>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2015/04/18/think-about-weidian-bussiness/">微店引发的互联网模式思考</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/04/18/kaggle-bike/">Kaggle入门总结</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/02/16/random-forest/">random forest</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/02/10/feature-hashing/">机器学习技巧之feature_hashing</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/02/07/git-practices/">git 实践</a>
      </li>
    
  </ul>
</section>






  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  messageStyle: "none",
  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

<p>
  Copyright &copy; 2015 - 阿波 -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'hbwu';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://whbzju.github.com/blog/2015/02/16/random-forest/';
        var disqus_url = 'http://whbzju.github.com/blog/2015/02/16/random-forest/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>











</body>
</html>
