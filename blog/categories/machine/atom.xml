<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: machine | 知行录]]></title>
  <link href="http://whbzju.github.com/blog/categories/machine/atom.xml" rel="self"/>
  <link href="http://whbzju.github.com/"/>
  <updated>2014-11-22T23:44:18+08:00</updated>
  <id>http://whbzju.github.com/</id>
  <author>
    <name><![CDATA[阿波]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[聚类算法中常见的距离计算方法]]></title>
    <link href="http://whbzju.github.com/blog/2014/11/22/ml-distance-measure/"/>
    <updated>2014-11-22T22:01:00+08:00</updated>
    <id>http://whbzju.github.com/blog/2014/11/22/ml-distance-measure</id>
    <content type="html"><![CDATA[<h2 id="section">概述</h2>
<p>在面对聚类问题时，选择何种距离计算方法求相似度是一个basic question。文献[1]中提到了N多计算方法，从大类来看有以下几种：</p>

<ul>
  <li>$L_p$ Minkowski家族</li>
  <li>$ L_1 $ 家族</li>
  <li>Intersection 家族</li>
  <li>Inner Product家族</li>
  <li>etl
简单算一下大概有40+个计算方法，其中有好多没有听过。好在工业界一般只涉及到几个，本文将按自己理解大致介绍下这些方法及应用情况。</li>
</ul>

<h2 id="section-1">距离的类型和尺度</h2>
<p>类型：</p>

<ul>
  <li>二进制（binary）</li>
  <li>离散值（Discrete）</li>
  <li>连续值(Continuous)</li>
</ul>

<p>尺度：</p>

<ul>
  <li>定性：比如同义：red、green、black，比如顺序：高、中、低</li>
  <li>定量：
  a) interval
  b) ratio
距离的类型和尺度非常重要，影响后续聚类算法的选择。</li>
</ul>

<h2 id="section-2">距离计算方法定义</h2>
<p>严谨的定义参考[4]，通俗来讲，在一个空间内，距离计算方法满足以下4个公理。</p>

<ol>
  <li>$d(x,y) ≥ 0$</li>
  <li>$ d(x,y)=0$ if $x=y$</li>
  <li>$ d(x, y) = d(y, x)$ (distance is symmetric)</li>
  <li>$d(x, y) ≤ d(x, z) + d(z, y)$ (the triangle inequality).</li>
</ol>

<p>在欧式空间，第四个公理可以直观理解为两点之间距离最短。在其他情况需要一些证明才能推导。</p>

<h2 id="section-3">常见的距离计算方法</h2>

<h3 id="lr-norm">Lr norm</h3>
<p>在n维空间，其计算公式如下：</p>

<p>$d(x,y)=(\sum_{k=1}^{n} |x_k-y_k| ^r)^{1/r}$</p>

<ul>
  <li>
    <p>欧式距离
当r=2，这就是我们熟悉的欧式距离，其聚类形状在二维空间是一个圆。归属于$L_2$ norm</p>
  </li>
  <li>
    <p>曼哈顿距离
r=1，归属于$L_1$ norm，其名字的来源与该距离计算过程有关。该距离类似在x和y的每个维度上沿grid line上travel，类似曼哈顿的街道。</p>
  </li>
  <li>
    <p>$L_∞$ norm
当r不断变大，该式中只有max $|x_i-y_i|$项起作用，故又称L_max norm</p>
  </li>
</ul>

<h3 id="jaccard-distance">Jaccard Distance</h3>
<p>类似于相识度，x和y每个维度上相同的值的个数/总的维度。</p>

<p>The comparison of two binary vectors, p and q, leads to four quantities: </p>

<ul>
  <li>M01 = the number of positions where p was 0 and q was 1 </li>
  <li>M10 = the number of positions where p was 1 and q was 0 </li>
  <li>M00 = the number of positions where p was 0 and q was 0 </li>
  <li>M11 = the number of positions where p was 1 and q was 1 </li>
</ul>

<p>The simplest similarity coefficient is the simple matching coefficient </p>

<p>$ J = (M11) / (M01 + M10 + M11) $ </p>

<p>如：</p>

<ul>
  <li>a = 1 0 0 0 0 0 0 0 0 0</li>
  <li>b = 0 0 0 0 0 0 1 0 0 1
J = 0</li>
</ul>

<h3 id="cosine-distance">cosine Distance</h3>
<p>即余弦公式。求x和y两个特征向量的夹角。
cos( d1, d2 ) = (d1 • d2) / ||d1|| ||d2|| </p>

<h3 id="edit-distance">Edit Distance</h3>
<p>一般适用于String point。通过不断的删除和添加单个字符来计算两个string之间的距离。</p>

<h3 id="hamming-distance">Hamming Distance</h3>
<p>pass</p>

<h2 id="section-4">参考</h2>

<ul>
  <li>[1] Comprehensive survey on distance/similarity measures between probability density functions. SH Cha
City, 2007 - csis.pace.edu</li>
  <li>[2] An Introduction to Cluster Analysis for Data Mining</li>
  <li>[3] Unsupervised and Semi-supervised Clustering:
a Brief Survey</li>
  <li>[4] Mining of Massive Datasets - chapter 3</li>
</ul>
]]></content>
  </entry>
  
</feed>
